---
phase: 07-storage-migration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - functions/api/upload-url.ts
  - src/types/cloud.ts
autonomous: true
user_setup:
  - service: cloudflare-r2
    why: "Secure object storage with zero egress fees"
    env_vars:
      - name: R2_ACCESS_KEY_ID
        source: "Cloudflare Dashboard → R2 → Manage R2 API Tokens → Create API Token"
      - name: R2_SECRET_ACCESS_KEY
        source: "Cloudflare Dashboard → R2 → Manage R2 API Tokens → Create API Token"
      - name: CF_ACCOUNT_ID
        source: "Cloudflare Dashboard → Workers & Pages → Account ID (right sidebar)"
      - name: R2_BUCKET_NAME
        source: "Name of the R2 bucket you created"
    account_setup:
      - url: "https://dash.cloudflare.com/sign-up"
        skip_if: "Already have Cloudflare account"
    dashboard_config:
      - task: "Create R2 bucket"
        location: "Cloudflare Dashboard → R2 → Create bucket"
        details: "Name: formcheck-recordings (or your choice), Location: Automatic"
      - task: "Create R2 API token"
        location: "Cloudflare Dashboard → R2 → Manage R2 API Tokens → Create API Token"
        details: "Permissions: Object Read & Write, Specify bucket: your bucket name"
      - task: "Configure CORS for R2 bucket"
        location: "Cloudflare Dashboard → R2 → your-bucket → Settings → CORS Policy"
        details: |
          Add this CORS policy:
          [
            {
              "AllowedOrigins": ["http://localhost:5173", "https://your-domain.com"],
              "AllowedMethods": ["PUT", "GET", "HEAD"],
              "AllowedHeaders": ["Content-Type", "Content-Length"],
              "ExposeHeaders": ["ETag"],
              "MaxAgeSeconds": 3600
            }
          ]
    local_dev:
      - "wrangler pages dev ./dist --binding R2_ACCESS_KEY_ID=xxx R2_SECRET_ACCESS_KEY=xxx CF_ACCOUNT_ID=xxx R2_BUCKET_NAME=xxx"
---

<objective>
Create the backend infrastructure for secure R2 uploads using presigned URLs.

Purpose: Establish the foundation that keeps credentials server-side. The Pages Function generates presigned URLs, and we define TypeScript types that the rest of the migration will use.

Output: Working Pages Function endpoint and cloud types ready for frontend integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-storage-migration/07-RESEARCH.md

# Existing S3 types to understand what we're replacing:
@src/types/s3.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create cloud types</name>
  <files>src/types/cloud.ts</files>
  <action>
Create TypeScript types for the new cloud upload system. Key difference from s3.ts: NO credentials in CloudConfig - the frontend only needs to know if cloud upload is enabled.

Types needed:
- `CloudConfig`: Just `{ enabled: boolean }` - no credentials stored client-side
- `UploadProgress`: Same as s3.ts `{ loaded: number, total: number, percentage: number }`
- `UploadStatus`: Same as s3.ts `'pending' | 'uploading' | 'complete' | 'failed'`
- `UploadResult`: Same as s3.ts `{ success: boolean, url?: string, error?: string }`
- `PresignedUrlResponse`: `{ uploadUrl: string, objectKey: string }` - response from Pages Function

Keep the same patterns as s3.ts for UploadProgress/Status/Result so the hook migration is straightforward.
  </action>
  <verify>tsc --noEmit passes with no errors</verify>
  <done>cloud.ts exports all 5 types, no TypeScript errors</done>
</task>

<task type="auto">
  <name>Task 2: Create Pages Function for presigned URL generation</name>
  <files>functions/api/upload-url.ts</files>
  <action>
Create Cloudflare Pages Function that generates presigned upload URLs using aws4fetch.

Implementation:
1. Install aws4fetch: `npm install aws4fetch`
2. Create `functions/api/upload-url.ts` (this path maps to `/api/upload-url` endpoint)
3. Export `onRequestPost` handler that:
   - Reads `{ fileName, contentType }` from request JSON body
   - Creates AwsClient with R2 credentials from `context.env`
   - Generates presigned PUT URL with 1-hour expiry (3600 seconds)
   - Returns `{ uploadUrl, objectKey }` as JSON

Use exact pattern from 07-RESEARCH.md code examples:
```typescript
import { AwsClient } from 'aws4fetch';

interface Env {
  R2_ACCESS_KEY_ID: string;
  R2_SECRET_ACCESS_KEY: string;
  CF_ACCOUNT_ID: string;
  R2_BUCKET_NAME: string;
}

export const onRequestPost: PagesFunction<Env> = async (context) => {
  // ... implementation from research
};
```

Object key format: `formcheck/{fileName}` (prefix for organization in bucket).

Error handling: Return 400 for missing fileName/contentType, 500 for signing failures.
  </action>
  <verify>
1. npm install aws4fetch succeeds
2. functions/api/upload-url.ts exists with correct structure
3. tsc --noEmit passes (may need to create env.d.ts for PagesFunction type)
  </verify>
  <done>
- aws4fetch installed in package.json
- Pages Function exports onRequestPost
- Reads env vars from context.env (not hardcoded)
- Returns presigned URL and object key
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm install` succeeds (aws4fetch added)
- [ ] `npm run build` succeeds without errors
- [ ] `tsc --noEmit` passes
- [ ] functions/api/upload-url.ts exists with proper structure
- [ ] src/types/cloud.ts exports all required types
</verification>

<success_criteria>
- aws4fetch dependency added to package.json
- Pages Function created at functions/api/upload-url.ts
- Cloud types defined in src/types/cloud.ts
- No TypeScript errors
- Foundation ready for Plan 02 (upload utility and hook)
</success_criteria>

<output>
After completion, create `.planning/phases/07-storage-migration/07-01-SUMMARY.md`
</output>
